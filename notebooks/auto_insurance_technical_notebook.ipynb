{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Insurance Analysis\n",
    "\n",
    "## Technical Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goals\n",
    "\n",
    "- Analyze auto insurance data.\n",
    "- Build a logistic regression model to predict crash probability for auto insurance customers.\n",
    "- Build a linear regression model to predict crash cost for auto insurance customers.\n",
    "- Use model results to develop crash percentage, assign customers to new risk profiles, and risk probability percentages.\n",
    "- Determine cost of premiums based on customer risk profiles and risk probability percentages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data\n",
    "\n",
    "The dataset for this project contains 6044 records of auto insurance data. Each record\n",
    "represents a customer at an auto insurance company. Using this data, we will be able to ascertain what\n",
    "influences the likelihood of a car crash. Then subsequently, we will be able to determine the cost to resolve a claim. The data in this project is the typical type of corporate data you would receive from a company in the insurance field-- a typical flat file from client records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "%run ../python_files/imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cleaned data from our exploratory data analysis\n",
    "%run ../python_files/auto_insurance_eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "\n",
    "Here, we are building a logistic regression model to predict crash probability for auto insurance customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Implementation\n",
    "\n",
    "Our logistic regression model using our training data initially shows some good signs. We check the negative coefficients of some of the feature variables and see that they are all very close to 0, meaning we do not need to remove any variables due to that. We also see that the p-values of our feature variables show no red flags and are also very close to 0, meaning we do not need to remove any variables due to that. The final observation that we see is that 'urbanicity' was the feature variable with the strongest predictive power over our response variable, 'crash'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.Logit(y_train_log, x_train_log)\n",
    "logit_result = logit_model.fit()\n",
    "print(logit_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Fitting\n",
    "\n",
    "We use our model from above, which was built on the training data set, to test against our test data set below. This will help us evaluate the model performance of our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(x_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting Test Set Results and Calculating Accuracy\n",
    "\n",
    "Below, we use several metrics to evaluate the model performance of our logistic regression model, including the calculation of accuracy, a confusion matrix, a classification report, and a plot of a ROC curve. These performance evaluation techniques evaluate the training dataset against the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = logreg_model.predict(x_test_log)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg_model.score(x_test_log, y_test_log)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the calculation of the accuracy, 78% of the variability in 'crash' can be explained using our feature variables, which is promising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix\n",
    "\n",
    "The below confusion matrix results are telling us that we have 946 (830 + 116 = 946) correct predictions and 263 (200 + 63 = 263) incorrect predictions. The ratio of approximately 3.6 correct predictions to every 1 incorrect predictions is a good sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_test_log, y_pred_log)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretation of Results\n",
    "\n",
    "The below classification report and ROC curve further display the accuracy of our model against the test set and the number of correct predictions vs incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_log, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test_log, logreg_model.predict(x_test_log))\n",
    "fpr, tpr, thresholds = roc_curve(y_test_log, logreg_model.predict_proba(x_test_log)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model\n",
    "\n",
    "Here, we are building a simple linear regression model to predict crash cost for auto insurance customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Implementation\n",
    "\n",
    "Our simple linear regression model is showing many red flags. First, the r-squared value of 0.153 shows that this model only explains approximately 15% of the variability in this model, in relation to our response variable 'crash_cost'. Our adjusted r-squared value is also similarly low at 0.149, indicating that this model is very inaccurate. Next, we can closely examine our feature variables and observe issues there as well. 8 of our feature variables (mstatus, sex, education, job, car_type, red_car, car_age, tif_log) have extreme negative coefficients that are very far away from a value of 0, indicating they are hurting model performance by being included in this model. We also see that 8 of our feature variables (age, homekids, yoj, sex, job, car_type, oldclaim, bluebook_log) have very high p-values that are also not close to a value of 0, indicating they are also hurting our model perofrmance by being included in this model. We will further examine model performance below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = sm.OLS(y_train_lin, x_train_lin)\n",
    "linear_result = linear_model.fit()\n",
    "print(linear_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Fitting\n",
    "\n",
    "We use our model from above, which was built on the training data set, to test against our test data set below. This will help us evaluate the model performance of our simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_model = LinearRegression()\n",
    "linreg_model.fit(x_train_lin, y_train_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Results\n",
    "\n",
    "Below, we use several metrics to evaluate the model performance of our simple linear regression model, including the calculation of r-squared value, the calculation of root mean squared error (RMSE) value, the calculation of mean absolute error value (MAE), and a plot of the model residuals. These performance evaluation techniques evaluate the training dataset against the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate r-squared value\n",
    "\n",
    "y_pred_lin = linreg_model.predict(x_test_lin)\n",
    "print('Linear Regression R squared\": %.4f' % linreg_model.score(x_test_lin, y_test_lin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the calculation of the r-squared value, only approximately 6% of the variability in crash_cost can be explained using our feature variables, which is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate root mean squared error (RMSE) value\n",
    "\n",
    "mse_lin = mean_squared_error(y_pred_lin, y_test_lin)\n",
    "rmse_lin = np.sqrt(mse_lin)\n",
    "print('Linear Regression RMSE: %.4f' % rmse_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the calculation of root mean squared error (RMSE), our model was able to predict that the value of every crash in the test set was within approximately $3814 of the real price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean absolute error (MAE) value\n",
    "\n",
    "mae_lin = mean_absolute_error(y_pred_lin, y_test_lin)\n",
    "print('Linear Regression MAE: %.4f' % mae_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of mean absolute error (MAE) was also concerning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot of Residuals\n",
    "\n",
    "visualizer = ResidualsPlot(linreg_model)\n",
    "visualizer.fit(x_train_lin, y_train_lin)  # Fit the training data to the visualizer\n",
    "visualizer.score(x_test_lin, y_test_lin)  # Evaluate the model on the test data\n",
    "visualizer.show()                         # Finalize and render the plot of residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot of the model residuals shows a bad relationship between predicted and actual values, which also proves that our model is not accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Conclusions\n",
    "\n",
    "Overall, we can conclude that our logistic regression model performed reaonsably well and is a good predictor of our 'crash' response variable. On the other hand, our simple linear regression model performed very poorly and is a bad predictor of our 'crash_cost' response variable. In future work, we can certainly make improvements to each model and consider whether to use more or less feature variables, or use other modeling techniques to improve performance.\n",
    "\n",
    "From here, we are able to use to modeling results of our logistic regression model to approxmiate crash percentage. With that, we can build risk profiles for our entire customer base and decide which are risky vs not risky drivers. With customer risk profiles, we can them assign customers a risk probability percentage that determines the likelihood that they get into a future crash. Lastly, using customer risk profiles and customer risk probability percentages, we can determine the cost of premiums for each of our customers.\n",
    "\n",
    "For further analysis, please review our 'presentation slides' located at the following link: https://prezi.com/view/1bE0LMc8xoJqwupO7EOy/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
